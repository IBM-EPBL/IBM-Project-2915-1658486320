{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjahIm7svvlw",
        "outputId": "47a30df5-233c-4339-f29d-f23096d6a808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/archive (1)/Dataset\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nbvNk2PwEKp",
        "outputId": "0e1c0b36-cdbc-4a28-a51d-8916ee30df0f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/drive/MyDrive/archive (1)/Dataset, /content/drive/MyDrive/archive (1)/Dataset.zip or /content/drive/MyDrive/archive (1)/Dataset.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "importing Required libraries"
      ],
      "metadata": {
        "id": "Ay42pJqawkgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "FxNLPikKwrIL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define parameters and arguments for ImageDataGeneratior"
      ],
      "metadata": {
        "id": "4a5m_IOLwyBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen=ImageDataGenerator(rescale=1./255,\n",
        "                                 shear_range=0.2,\n",
        "                                 rotation_range=180,\n",
        "                                 zoom_range=0.2,\n",
        "                                 horizontal_flip=True)\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "kvWmCg-pwziB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying ImageDataGenerator"
      ],
      "metadata": {
        "id": "ieagSmOGw53x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = test_datagen.flow_from_directory(r'/content/drive/MyDrive/archive (1)/Dataset/Dataset/test_set',\n",
        "                                          target_size=(128,128),\n",
        "                                          batch_size=32,\n",
        "                                          class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWzVyFMew7qq",
        "outputId": "97055840-653a-4fb3-b34e-5b2682c4a8e7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 121 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train_datagen.flow_from_directory(r'/content/drive/MyDrive/archive (1)/Dataset/Dataset/train_set',\n",
        "                                          target_size=(128,128),\n",
        "                                          batch_size=32,\n",
        "                                          class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4GvdCoZxOAS",
        "outputId": "c3f06b51-3bd1-4de5-bccd-82d0e87c5baa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 436 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model building"
      ],
      "metadata": {
        "id": "0v4DeVF8x18C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import model building libraries\n",
        "\n",
        "#to define linear initialisation import sequential\n",
        "from keras.models import Sequential\n",
        "#to add layer import Dense\n",
        "from keras.layers import Dense\n",
        "#to create convolution kernel import convolution2D\n",
        "from keras.layers import Convolution2D\n",
        "#import Maxpooling layer\n",
        "from keras.layers import MaxPool2D\n",
        "#import flatten layer\n",
        "from keras.layers import Flatten\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "thal4JmCx6gL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize the model\n",
        "model=Sequential()"
      ],
      "metadata": {
        "id": "pPUi3rXSyBpM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers.pooling.max_pooling2d import MaxPooling2D\n",
        "#add convolution layer\n",
        "model.add(Convolution2D(32,(3,3),input_shape=(128,128,3),activation='relu'))\n",
        "#add maxpooling layer\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#add flatten layer\n",
        "model.add(Flatten())"
      ],
      "metadata": {
        "id": "QrCF42ugyFhT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add hidden layer\n",
        "model.add(Dense(150,activation='relu'))\n",
        "#add output layer\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "sIqYf0zQyYqa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#configure the learning process\n",
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = \"adam\",\n",
        "              metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "Vo8oynSEyr_S"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training the model\n",
        "model.fit(x_train,steps_per_epoch=14,\n",
        "                    epochs=10,validation_data=x_test,\n",
        "                    validation_steps=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8B2D4UVqyxDK",
        "outputId": "3a44a013-90e2-402b-c4ec-d1585f8b6bbf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "14/14 [==============================] - 140s 10s/step - loss: 1.4526 - accuracy: 0.7110 - val_loss: 0.5803 - val_accuracy: 0.8595\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 27s 2s/step - loss: 0.4439 - accuracy: 0.8601 - val_loss: 0.1186 - val_accuracy: 0.9587\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.2248 - accuracy: 0.9197 - val_loss: 0.0921 - val_accuracy: 0.9587\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.1869 - accuracy: 0.9174 - val_loss: 0.1060 - val_accuracy: 0.9587\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.1868 - accuracy: 0.9266 - val_loss: 0.0807 - val_accuracy: 0.9669\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 30s 2s/step - loss: 0.1885 - accuracy: 0.9128 - val_loss: 0.1186 - val_accuracy: 0.9421\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 27s 2s/step - loss: 0.1695 - accuracy: 0.9289 - val_loss: 0.0925 - val_accuracy: 0.9669\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 27s 2s/step - loss: 0.1796 - accuracy: 0.9243 - val_loss: 0.1459 - val_accuracy: 0.9504\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.2033 - accuracy: 0.9014 - val_loss: 0.0760 - val_accuracy: 0.9752\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.1637 - accuracy: 0.9266 - val_loss: 0.0722 - val_accuracy: 0.9752\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc357c63350>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save the model\n",
        "model.save(\"/content/drive/MyDrive/archive (1)/forest1.h5\")"
      ],
      "metadata": {
        "id": "0KTWWHGhy8p0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import load_model from keras.model\n",
        "from keras.models import load_model\n",
        "#import image class from keras\n",
        "from tensorflow.keras.preprocessing import image\n",
        "#import numpy\n",
        "import numpy as np\n",
        "#import cv2\n",
        "import cv2"
      ],
      "metadata": {
        "id": "fXB0_VOe0nAV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the saved model\n",
        "model = load_model(\"/content/drive/MyDrive/archive (1)/forest1.h5\")"
      ],
      "metadata": {
        "id": "gXBfkNct0r6L"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img=image.load_img(r'/content/drive/MyDrive/archive (1)/Dataset/Dataset/test_set/with fire/GettyImages_482867948.0.jpg')\n",
        "x=image.img_to_array(img)\n",
        "res = cv2.resize(x, dsize=(128,128),interpolation=cv2.INTER_CUBIC)\n",
        "x=np.expand_dims(res,axis=0)"
      ],
      "metadata": {
        "id": "zFeLBooR0z8z"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv9HpNBU1fj-",
        "outputId": "c90a65d1-0606-4001-82f6-326f601eec43"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 169ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfDcSwF018C7",
        "outputId": "38198aa8-bf1a-4648-f2e6-fcfadc79c3a2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}